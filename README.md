# 📘 밑바닥부터 시작하는 딥러닝 (Deep Learning from Scratch)

이 저장소는 '밑바닥부터 시작하는 딥러닝 1권'을 공부하며 작성한 코드와 학습 기록을 저장하는 공간입니다.
라이브러리에 의존하지 않고, 파이썬과 수치 계산(NumPy)만으로 딥러닝 구조를 직접 구현해보는 것을 목표로 합니다.

## 🛠️ 개발 환경 (Environment)
* **Language**: Python 3.10
* **Library**: NumPy, Matplotlib
* **Tools**: VS Code, Miniconda

## 📂 학습 목차 (Curriculum)
### 📅 2025-12-16 (Day 1)
#### Chapter 1. 헬로 파이썬
* 파이썬 기본 문법 및 NumPy 브로드캐스팅 실습
* Matplotlib을 이용한 그래프 시각화 (`sin`, `cos` 함수 등)

#### Chapter 2. 퍼셉트론 (Perceptron)
* AND, NAND, OR 게이트 구현
* XOR 게이트의 한계와 다층 퍼셉트론(MLP)의 개념 이해

#### 📝 트러블 슈팅 (Trouble Shooting)
* **2025-12-16**: `matplotlib` 경로 에러 해결 (Raw String `r` 사용)

---

### 📅 2025-12-19 (Day 2)
**학습 목표:** 퍼셉트론의 원리 이해와 다층 퍼셉트론(MLP) 구현

#### 1. 학습 내용
* **퍼셉트론 구현:**
    * 기본 논리 게이트(`AND`, `NAND`, `OR`)를 가중치($w$)와 편향($b$) 도입하여 구현함.
    * 퍼셉트론이 직선(선형)으로 영역을 나누는 원리를 시각적으로 이해함.
* **XOR 게이트와 한계:**
    * 단층 퍼셉트론으로는 비선형 영역(XOR)을 분리할 수 없음을 확인.
    * `AND`, `NAND`, `OR` 게이트를 층으로 쌓아(Layering) XOR 게이트를 완성함 -> **다층 퍼셉트론(MLP)**의 개념 정립.
* **활성화 함수 기초:**
    * 계단 함수(Step Function) 구현 및 시각화.
    * 계단 함수와 시그모이드 함수의 차이점(매끄러움, 연속성)에 대해 맛보기 학습.

#### 2. 트러블 슈팅 (Trouble Shooting)
* **문제:** `np.array(x > 0, dtype=np.int)` 실행 시 `AttributeError: module 'numpy' has no attribute 'int'` 발생.
* **원인:** NumPy 버전 업데이트로 `np.int` 별칭(Alias)이 삭제됨. (개정판 이전으로 공부 중이기에 발생함.)
* **해결:** `np.int`를 파이썬 내장 `int` 또는 `np.int32`로 수정하여 해결 완료.

---

### 📅 2025-12-23 (Day 3)
**학습 목표:** 신경망(Neural Network)의 신호 전달 과정 구현과 행렬 곱의 이해

#### 1. 학습 내용
* **활성화 함수의 중요성 (Why Non-linear?):**
    * 선형 함수($h(x)=cx$)를 사용하면 층을 아무리 깊게 쌓아도 결국 '하나의 은닉층'과 똑같아짐을 이해함.
    * 딥러닝의 표현력을 높이려면 시그모이드, ReLU 같은 **비선형 함수**가 필수적임.
* **다차원 배열의 계산 (Matrix Multiplication):**
    * `np.dot`을 이용해 입력값과 가중치의 계산을 한 번에 처리하는 원리 학습.
    * **형상(Shape) 맞추기 규칙:** 행렬 곱 $A \times B$에서 A의 열 수와 B의 행 수가 같아야 함을 이해. (예: `(1, 2) * (2, 3) -> (1, 3)`)
* **3층 신경망 구현 (3.4.2 ~ 3.4.3):**
    * `입력($X$) -> 가중치 결합($XW+B$) -> 활성화($Z$)`로 이어지는 신호 전달 흐름을 코드로 구현.
    * 은닉층(Hidden Layer)이 데이터의 특징(Feature)을 추출하고 변환하는 역할을 한다는 직관 획득.
* **출력층 설계:**
    * **항등 함수(Identity Function):** 입력을 그대로 출력. 주로 회귀(숫자 예측) 문제에서 사용함. (다음 시간에 배울 소프트맥스와 대비)

#### 2. 학습 마인드셋 (Insight)
* **"수식은 암기하는 것이 아니라 도구로 가져다 쓰는 것"**
* 복잡한 수식 증명보다 데이터가 흘러가는 **구조(Flow)와 구현**에 집중하기로 함.
* 모르는 게 나오면 그때 찾아보는 **JIT(Just-In-Time) 학습법** 적용.

---

### 📅 2026-01-01 (Day 4)
**학습 목표:** 신경망 출력층의 설계(Softmax)와 MNIST 추론 실습 준비 (환경 설정)

#### 1. 핵심 이론 학습
* **소프트맥스 함수 (Softmax):**
    * 분류(Classification) 문제에서 출력값을 **'확률(Probability)'**로 변환해주는 함수.
    * **핵심 원리:** 전체 합계에서 내 점수가 차지하는 '비율'을 계산 ($y_k = \frac{\exp(a_k)}{\sum \exp(a_i)}$).
    * **오버플로(Overflow) 방지:** 지수 함수($e^x$) 폭주를 막기 위해, 입력값 중 최댓값을 빼주는 테크닉($x - c$)을 적용함.
* **출력층 설계:**
    * **회귀(Regression):** 항등 함수 사용 (숫자 그대로 출력).
    * **분류(Classification):** 소프트맥스 함수 사용 (확률 출력).
    * **뉴런 개수:** 분류하고 싶은 클래스 수와 동일하게 설정 (예: MNIST는 0~9니까 10개).
* **용어 정리:**
    * **순전파 (Forward Propagation):** 입력에서 출력으로 신호가 한 방향으로 흐르는 과정. 추론(Inference) 단계의 핵심 메커니즘.

#### 2. 실전 트러블 슈팅 (Debug Log)
* **문제 상황:** `dataset.mnist` 모듈을 불러오지 못하는 `ModuleNotFoundError` 발생.
* **원인:**
    1. `dataset` 폴더가 작업 경로에 없었음 (파일 위치 문제).
    2. 파이썬 실행 경로(`sys.path`)가 소스 코드 위치와 일치하지 않음.
* **해결:**
    1. 깃허브에서 `dataset` 폴더를 다운로드하여 소스 코드 옆에 배치.
    2. `sys.path.append`로 경로를 잡아주거나, 폴더 구조를 맞춰서 해결함.
    * **Lesson:** "코딩은 파일 위치(경로) 싸움이다. 파이썬이 파일을 못 찾으면 `sys.path`와 폴더 구조부터 확인하자. 혹은 파일을 직접 열어서 확인해보자."

#### 3. 오늘의 인사이트
* **"오버플로를 수학적 이동으로 해결하다니!"**
    * 컴퓨터의 한계(무한대 표현 불가)를 수식의 성질(비율 불변)을 이용해 해결하는 공학적 접근법을 배움.
* **"순전파는 문제 풀기, 역전파는 오답 노트"**
    * 추론(Forward)과 학습(Backward)의 관계를 직관적으로 이해함.

---